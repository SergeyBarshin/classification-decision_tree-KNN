# DecisionTree Implementation

Этот проект представляет собой реализацию дерева решений (DecisionTree) на Python.
Класс DecisionTree наследуется от sklearn.BaseEstimator и поддерживает как задачи классификации, так и регрессии.

### Установка

Для работы требуется Python 3 и следующие зависимости:
`pip install numpy scikit-learn`

## Реализация DecisionTree

- Класс будет наследован от `sklearn.BaseEstimator`

- Параметры конструктора:

  - `max_depth` - максимальная глубина дерева (`numpy.inf` по умолчанию)
  - `min_samples_split` - минимальное колличество объектов при разделении (2 по умолчанию)
  - `criterion` - критерий для разделения. `gini` или `entropy` для классификации, `variance` или `mad_median` для регрессии. (`gini` по умолчанию)

- класс будет содержать методы `fit`, `predict`, `predict_proba`
  - `fit`: принимает матрицу $X$ и целевой вектор $y$ (`numpy.ndarray`) и возвращает объект `DecisionTree` обученный на $(X, y)$ в соответсвии параметрам из конструктора.
  - `predict_proba`: принимает матрицу $X$ и возвращет матрицу $P$, размером $X.shape[0] \ x \ K$, где $K$ число класслв и $p_{ij}$ вероятноть того, что $i$-й столбец $x$ принажлежит классу $j \in \{1,...,K\}$.
  - `predict`: принимает матрицу $X$ возвращает предсказанный вектор. В случае классификации, интсанс $x_i$ попавший в лист $L$ будет классом, который наиболее частво встречается среди инстансов $L$. В случае регресии, это будет среднее значение всех экземпляров в $L$.

#### Критерии `criterion`

Критерий - функция которую нужно максимизировать, чтобы найти оптимальное разделение на данном узле: $$Q(X,j,t)=F(x) - \frac{X_l}{X}F(X_l) - \frac{X_r}{X}F(x_r),$$
где $X$ - множество объектов в текущем узле. $X_l$ и $X_r$ - две подгруппы, на которые делится $X$ в зависимости от условия разбиения $[x_j < t]$ (по признаку $j$ и порогу $t$. $F(X)$ - критерий разбиения.

_Для классификации:_ пусть $p_i$ - доля экземпляров $i$-го класса в $X$.

- `gini`: критерий джини $F(x) = 1 - \sum_{i=1}^{K}p_i^2$.
- `entropy`: $F(x) = - \sum_{i=1}^{K}p_ilog_2(p_i)$.

_Для регресии:_ $y_j=y(x_j)$ - целевое значение для истанса $x_j$, $y=(y_1,...,y_{|X|})$ - целевой вектор.

- `variance`: Дисперсия (СКО) $F(x) = \frac{1}{|X|} \sum_{x_j \in X}(y_j - \frac{1}{|X|}\sum_{x_i \in X}y_i)^2$.
- `mad_median`: Среднее отклонение от медианы $F(x) = \frac{1}{|X|} \sum_{x_j \in X}|y_i - med(y)|$.

## Структура проекта

```
project_root/
│── decision_tree/
│   ├── __init__.py
│   ├── tree.py  # Основная реализация DecisionTree
│── main.py  # Пример использования модели
│── README.md  # Документация
|── test.ipynb # Ноутбук с тестом модели
```
